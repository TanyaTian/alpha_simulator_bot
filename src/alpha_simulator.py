import queue
import time
import csv
import requests
import os
import ast
import json
import threading
import heapq
import random
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Union
from collections import deque
from pytz import timezone
from logger import Logger  
from datetime import datetime, timedelta
from signal_manager import SignalManager
from dao import SimulationTasksDAO  
from dao import AlphaListPendingSimulatedDAO
from config_manager import config_manager

@dataclass
class PendingSimulation:
    """
    è¡¨ç¤ºä¸€ä¸ªå¾…æ£€æŸ¥çš„æ¨¡æ‹Ÿä»»åŠ¡
    ä½¿ç”¨æœ€å°å †æŒ‰ next_check_time æ’åº
    """
    next_check_time: float
    location_url: str
    retry_count: int
    record_ids: List[int]  # å…³è”çš„æ•°æ®åº“ record id
    backoff_factor: int = 2  # æŒ‡æ•°é€€é¿å› å­
    max_delay: int = 300     # æœ€å¤§å»¶è¿Ÿ 5 åˆ†é’Ÿ

    def __lt__(self, other):
        return self.next_check_time < other.next_check_time

class AlphaSimulator:
    """Alphaæ¨¡æ‹Ÿå™¨ç±»ï¼Œç”¨äºç®¡ç†é‡åŒ–ç­–ç•¥çš„æ¨¡æ‹Ÿè¿‡ç¨‹"""

    TIMESTAMP_FORMAT = "%Y%m%d_%H%M%S"
    FILE_CONFIG = {
        "input_file": "alpha_list_pending_simulated.csv",
        "fail_file": "fail_alphas.csv",
        "output_file": "simulated_alphas.csv",  # åŸºç¡€æ–‡ä»¶å
        "state_file": "simulator_state.json"
    }

    def __init__(self, signal_manager=None):
        """åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨

        Args:
            max_concurrent (int): æœ€å¤§å¹¶å‘æ¨¡æ‹Ÿæ•°é‡
            username (str): ç™»å½•ç”¨æˆ·å
            password (str): ç™»å½•å¯†ç 
            batch_number_for_every_queue (int): æ¯æ‰¹å¤„ç†æ•°é‡
        """
        self.running = True

        # åˆ›å»º Logger å®ä¾‹
        self.logger = Logger()

        # æ³¨å†Œä¿¡å·å¤„ç†
        if signal_manager:
            signal_manager.add_handler(self.signal_handler)
        else:
            self.logger.warning("æœªæä¾› SignalManager,AlphaSimulator æ— æ³•æ³¨å†Œä¿¡å·å¤„ç†å‡½æ•°")

        # æ³¨å†Œé…ç½®è§‚å¯Ÿè€…
        self._config_observer_handle = config_manager.on_config_change(self._handle_config_change)
        
        # ä»é…ç½®ä¸­å¿ƒè·å–å‚æ•°
        self._load_config_from_manager()
        
        # æ„å»ºåŸºç¡€è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        self.data_dir = os.path.join(project_root, 'data')

        # è‡ªåŠ¨åˆ›å»ºdataç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(self.data_dir, exist_ok=True)

        # æ„å»ºæ–‡ä»¶è·¯å¾„ä½“ç³»
        self.state_file = os.path.join(self.data_dir, self.FILE_CONFIG["state_file"])


        # åˆå§‹åŒ–DAO
        self.alpha_list_pending_simulated_dao = AlphaListPendingSimulatedDAO()
        self.simulation_task_dao = SimulationTasksDAO()
        
        # åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—å’Œæ˜ å°„å­—å…¸
        self.simulation_heap: List[PendingSimulation] = []  # ä¼˜å…ˆé˜Ÿåˆ—
        self.active_simulations_dict = {}  # å­˜å‚¨location_urlåˆ°record_idsçš„æ˜ å°„
        self.active_update_time = time.time()
        self.lock = threading.Lock()  # ğŸ”’ æ–‡ä»¶å†™å…¥é”

        # åŠ è½½ä¸Šæ¬¡æœªå®Œæˆçš„ active_simulations
        self._load_previous_state()

    def signal_handler(self, signum, frame):
        self.logger.info(f"Received shutdown signal {signum}, , initiating shutdown...")
        self.running = False
        self.save_state()

    def _load_previous_state(self):
        if os.path.exists(self.state_file):
            with open(self.state_file, 'r') as f:
                state = json.load(f)
                urls = state.get("active_simulations", [])
                for url in urls:
                    # åˆå§‹ retry_count=0ï¼Œé¦–æ¬¡æ£€æŸ¥å»¶è¿Ÿ 5 ç§’
                    heapq.heappush(self.simulation_heap, PendingSimulation(
                        next_check_time=time.time() + 5,
                        location_url=url,
                        retry_count=0,
                        record_ids=[]  # ä¹‹å‰çš„record_idsä¿¡æ¯ä¸¢å¤±ï¼Œè®¾ç½®ä¸ºç©º
                    ))
                self.logger.info(f"Loaded {len(urls)} previous simulations into heap.")


    def _load_config_from_manager(self):
        """ä»é…ç½®ä¸­å¿ƒåŠ è½½è¿è¡Œæ—¶å‚æ•°"""
        config = config_manager._config  # ç›´æ¥è®¿é—®å†…éƒ¨é…ç½®
        
        # åŠ è½½æ ¸å¿ƒå‚æ•°ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
        self.max_concurrent = config.get('max_concurrent', 5)
        self.batch_number_for_every_queue = config.get('batch_number_for_every_queue', 100)
        self.batch_size = config.get('batch_size', 10)
        
        # åŠ è½½region_setå‚æ•°ï¼Œä½¿ç”¨collections.dequeå®ç°å¾ªç¯é˜Ÿåˆ—
        region_set = config.get('region_set', ['US'])
        if not isinstance(region_set, list):
            region_set = ['US']
        self.region_set = deque(region_set)
        
        # ä½¿ç”¨é…ç½®ä¸­å¿ƒçš„session
        self.session = config_manager.get_session()
        
        self.logger.info(f"Loaded config: max_concurrent={self.max_concurrent}, "
                        f"batch_number_for_every_queue={self.batch_number_for_every_queue}, "
                        f"batch_size={self.batch_size}")
    
    def _handle_config_change(self, new_config):
        """é…ç½®å˜æ›´å›è°ƒå¤„ç†"""
        self._load_config_from_manager()
        self.logger.info("Configuration reloaded due to config center update")
    
    def __del__(self):
        """ææ„å‡½æ•°æ¸…ç†è§‚å¯Ÿè€…æ³¨å†Œ"""
        if hasattr(self, '_config_observer_handle'):
            observer_list = config_manager._observers
            if self._handle_config_change in observer_list:
                observer_list.remove(self._handle_config_change)


    def simulate_alpha(self, alpha_list):
        """
        æ¨¡æ‹Ÿä¸€ç»„ alpha è¡¨è¾¾å¼ï¼Œé€šè¿‡ API æäº¤æ‰¹é‡æ¨¡æ‹Ÿè¯·æ±‚ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰ã€‚

        Args:
            alpha_list (list): åŒ…å«å¤šä¸ª alpha æ•°æ®çš„åˆ—è¡¨ï¼Œæ¯ä¸ª alpha æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« typeã€settings å’Œ regular å­—æ®µ
                - type: å­—ç¬¦ä¸²ï¼Œæ¨¡æ‹Ÿç±»å‹ï¼Œä¾‹å¦‚ "REGULAR"
                - settings: å­—å…¸ï¼Œæ¨¡æ‹Ÿè®¾ç½®ï¼Œä¾‹å¦‚ {'instrumentType': 'EQUITY', ...}
                - regular: å­—ç¬¦ä¸²ï¼Œalpha è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ "ts_quantile(winsorize(...), 22)"

        Returns:
            str or None: æ¨¡æ‹Ÿè¿›åº¦ URLï¼ˆlocation_urlï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
        """
        backoff = 5 # åˆå§‹ç­‰å¾…æ—¶é—´
        # å°† alpha_list è½¬æ¢ä¸º sim_data_listï¼Œç”¨äº API è¯·æ±‚
        sim_data_list = self.generate_sim_data(alpha_list)

        # å¦‚æœ sim_data_list ä¸ºç©ºï¼ˆä¾‹å¦‚ alpha_list ä¸­æ‰€æœ‰ alpha éƒ½æ— æ•ˆï¼‰ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›
        if not sim_data_list:
            self.logger.error("No valid simulation data generated from alpha_list")
            return None

        # åˆå§‹åŒ–é‡è¯•è®¡æ•°å™¨
        count = 0

        # é‡è¯•å¾ªç¯ï¼Œæœ€å¤šå°è¯• 35 æ¬¡
        while True:
            try:
                # ä½¿ç”¨ self.session å‘é€ POST è¯·æ±‚åˆ° WorldQuant Brain å¹³å°çš„ API
                response = self.session.post('https://api.worldquantbrain.com/simulations', json=sim_data_list)

                # æ£€æŸ¥ HTTP çŠ¶æ€ç ï¼Œå¦‚æœå¤±è´¥ï¼ˆä¾‹å¦‚ 4xx æˆ– 5xxï¼‰ï¼ŒæŠ›å‡ºå¼‚å¸¸
                response.raise_for_status()

                # æ£€æŸ¥å“åº”å¤´ä¸­æ˜¯å¦åŒ…å« Location å­—æ®µ
                if "Location" in response.headers:
                    # å¦‚æœæˆåŠŸè·å– Locationï¼Œè®°å½•æ—¥å¿—å¹¶è¿”å›
                    self.logger.info("Alpha batch location retrieved successfully.")
                    self.logger.info(f"Location: {response.headers['Location']}")
                    return response.headers['Location']

            except requests.exceptions.RequestException as e:
                # æ•è· HTTP è¯·æ±‚ç›¸å…³çš„å¼‚å¸¸ï¼ˆä¾‹å¦‚ç½‘ç»œé”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ï¼‰
                self.logger.error(f"Error in sending simulation request: {e}")

                # å¦‚æœé‡è¯•æ¬¡æ•°è¶…è¿‡ 35 æ¬¡ï¼Œé‡æ–°ç™»å½•å¹¶è·³å‡ºå¾ªç¯
                if count > 35:
                    # è°ƒç”¨ sign_in æ–¹æ³•é‡æ–°ç™»å½•
                    
                    self.session = config_manager.get_session()
                    self.logger.error("Error occurred too many times, skipping this alpha batch and re-logging in.")
                    break

                
                # âœ…æŒ‡æ•°é€€é¿ + æŠ–åŠ¨ï¼Œæœ€å¤§ç­‰å¾… 300s
                sleep_time = min(backoff * (2 ** (count - 1)), 300)
                sleep_time += random.uniform(0, 3)
                self.logger.error(f"Error in sending simulation request. Retrying after {sleep_time}s...")
                time.sleep(sleep_time)
                count += 1

        # å¦‚æœè¯·æ±‚å¤±è´¥ï¼ˆé‡è¯•æ¬¡æ•°è€—å°½ï¼‰ï¼Œè®°å½•é”™è¯¯
        self.logger.error(f"Simulation request failed after {count} attempts for alpha batch")
        return None
    
    def generate_sim_data(self, alpha_list):
        """
        å°† alpha_list è½¬æ¢ä¸º sim_data_listï¼Œç”¨äºæ‰¹é‡æ¨¡æ‹Ÿã€‚

        Args:
            alpha_list (list): åŒ…å«å¤šä¸ª alpha å­—å…¸çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« typeã€settings å’Œ regular å­—æ®µ
                - type: å­—ç¬¦ä¸²ï¼Œæ¨¡æ‹Ÿç±»å‹ï¼Œä¾‹å¦‚ "REGULAR"
                - settings: å­—å…¸ï¼Œæ¨¡æ‹Ÿè®¾ç½®ï¼Œä¾‹å¦‚ {'instrumentType': 'EQUITY', ...}
                - regular: å­—ç¬¦ä¸²ï¼Œalpha è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ "ts_quantile(winsorize(...), 22)"

        Returns:
            list: åŒ…å«å¤šä¸ª simulation_data å­—å…¸çš„åˆ—è¡¨ï¼Œæ ¼å¼ç¬¦åˆ API è¦æ±‚
        """
        sim_data_list = []

        for alpha in alpha_list:
            # ç¡®ä¿ alpha åŒ…å«å¿…è¦çš„å­—æ®µ
            if not all(key in alpha for key in ['type', 'settings', 'regular']):
                self.logger.error(f"Invalid alpha data, missing required fields: {alpha}")
                continue

            # ç›´æ¥ä½¿ç”¨ settings å­—æ®µï¼ˆæ•°æ®åº“è¿”å›çš„æ˜¯å­—å…¸ï¼‰
            settings = alpha['settings']
            if not isinstance(settings, dict):
                self.logger.error(f"Unexpected type for settings: {type(settings)}. Expected dict. Skipping this alpha.")
                continue

            # æ„é€  simulation_data å­—å…¸
            simulation_data = {
                'type': alpha['type'],
                'settings': settings,
                'regular': alpha['regular']
            }

            sim_data_list.append(simulation_data)

        self.logger.info(f"Generated sim_data_list with {len(sim_data_list)} entries")
        return sim_data_list
        
    def load_new_alpha_and_simulate(self):
        """
        ä»æ•°æ®åº“æ‰¹é‡æŸ¥è¯¢å¾…å›æµ‹alphaï¼Œç„¶åè¿›è¡Œæ¨¡æ‹Ÿ
        
        ä½¿ç”¨æ–°æ–¹æ³•fetch_pending_alphas_in_batchesä»æ•°æ®åº“æ‰¹é‡è·å–å¾…å›æµ‹alpha
        æ¯æ¬¡æŸ¥è¯¢çš„æ•°é‡ä¸ºself.batch_sizeï¼Œregionä¸ºregion_setçš„ç¬¬ä¸€ä¸ªå…ƒç´ 
        è°ƒç”¨åè½®è½¬region_setï¼Œå°†å½“å‰regionç§»åˆ°æœ€åä¸€ä¸ª

        Attributes:
            self.batch_size (int): æ¯æ¬¡æŸ¥è¯¢çš„æ•°é‡
            self.region_set (deque): åœ°åŒºå¾ªç¯é˜Ÿåˆ—
            self.dao (AlphaListPendingSimulatedDAO): æ•°æ®è®¿é—®å¯¹è±¡
            self.max_concurrent (int): æœ€å¤§å¹¶å‘æ¨¡æ‹Ÿæ•°é‡
            self.active_simulations (list): æ­£åœ¨è¿›è¡Œçš„æ¨¡æ‹Ÿä»»åŠ¡åˆ—è¡¨
            self.logger (Logger): æ—¥å¿—è®°å½•å™¨
        """
        # æ£€æŸ¥è¿è¡ŒçŠ¶æ€ï¼Œå¦‚æœ running ä¸º Falseï¼Œåˆ™é€€å‡º
        if not self.running:
            return

        # è·å–å½“å‰æ´»è·ƒæ•°ï¼ˆæ¥è‡ª heapï¼‰
        current_active = len(self.simulation_heap)
        target_concurrent = self.max_concurrent
        available_slots = target_concurrent - current_active

        if available_slots <= 0:
            self.logger.debug(f"Slots full: {current_active}/{target_concurrent}")
            return

        self.logger.info(f"Slots available: {available_slots}, trying to fill...")

        for _ in range(available_slots):
            try:
                # ä½¿ç”¨æ–°æ–¹æ³•ä»æ•°æ®åº“æ‰¹é‡è·å–å¾…å›æµ‹alpha
                db_records = self.fetch_pending_alphas_in_batches(self.batch_size)
                
                # å¦‚æœæ²¡æœ‰è·å–åˆ°alphaï¼Œç›´æ¥è¿”å›
                if not db_records:
                    self.logger.info("No pending alphas fetched from database.")
                    return

                # æå–éœ€è¦æ¨¡æ‹Ÿçš„æ•°æ®
                alpha_list = []
                record_ids = []
                for record in db_records:
                    try:
                        # å°è¯•ç±»å‹è½¬æ¢settingså­—æ®µ
                        if 'settings' in record:
                            if isinstance(record['settings'], str):
                                try:
                                    record['settings'] = ast.literal_eval(record['settings'])
                                except (ValueError, SyntaxError) as e:
                                    # è½¬æ¢å¤±è´¥æ—¶è®°å½•é”™è¯¯å¹¶è·³è¿‡æ­¤è®°å½•
                                    self.logger.error(f"ç±»å‹è½¬æ¢å¤±è´¥ (record id={record['id']}): {e}")
                                    continue
                            elif not isinstance(record['settings'], dict):
                                self.logger.error(f"settingså­—æ®µç±»å‹é”™è¯¯ (record id={record['id']}): æœŸæœ›å­—å…¸ç±»å‹, å®é™…æ˜¯ {type(record['settings'])}")
                                continue
                        
                        # æ„é€ alphaå¯¹è±¡
                        alpha = {
                            'type': record['type'],
                            'settings': record['settings'],
                            'regular': record['regular']
                        }
                        alpha_list.append(alpha)
                        record_ids.append(record['id'])
                        
                        # è®°å½•å½“å‰æ‰¹æ¬¡çš„ alpha ä¿¡æ¯
                        self.logger.info(f"  - ID: {record['id']}, Alpha: {record['regular'][:50]}... with settings: {record['settings']}")
                    except Exception as e:
                        self.logger.error(f"å¤„ç†recordæ—¶å‘ç”Ÿé”™è¯¯ (id={record['id']}): {e}")
                        continue

                # è°ƒç”¨ simulate_alphaï¼Œä¼ å…¥ alpha åˆ—è¡¨
                location_url = self.simulate_alpha(alpha_list)

                # å¦‚æœæ¨¡æ‹ŸæˆåŠŸï¼ˆè¿”å› location_urlï¼‰ï¼Œå°† URL æ·»åŠ åˆ° active_simulations
                if location_url:
                    # æäº¤æˆåŠŸï¼ŒåŠ å…¥ heapï¼Œ5 ç§’åé¦–æ¬¡æ£€æŸ¥
                    heapq.heappush(self.simulation_heap, PendingSimulation(
                        next_check_time=time.time() + 5,
                        location_url=location_url,
                        retry_count=0,
                        record_ids=record_ids
                    ))
                    # å­˜å‚¨location_urlåˆ°record_idsçš„æ˜ å°„
                    self.active_simulations_dict[location_url] = record_ids
                    self.active_update_time = time.time()
                    self.logger.info(f"Simulation started, location_url: {location_url}")
                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºæˆåŠŸ
                    self.alpha_list_pending_simulated_dao.batch_update_status_by_ids(record_ids, 'sent')
                else:
                    self.logger.warning("Simulation failed, no location_url returned")
                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºå¤±è´¥
                    self.alpha_list_pending_simulated_dao.batch_update_status_by_ids(record_ids, 'failed')

            except Exception as e:
                # æ•è·å…¶ä»–å¼‚å¸¸ï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
                self.logger.error(f"Error during simulation: {e}")
                # å°è¯•æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºå¤±è´¥
                if 'record_ids' in locals() and record_ids:
                    try:
                        self.alpha_list_pending_simulated_dao.batch_update_status_by_ids(record_ids, 'failed')
                    except Exception as db_error:
                        self.logger.error(f"Failed to update database status: {db_error}")
    
    def check_simulation_progress(self, simulation_progress_url)-> Union[List, None, bool]:
        """
        æ£€æŸ¥æ‰¹é‡æ¨¡æ‹Ÿçš„è¿›åº¦ï¼Œè·å– children åˆ—è¡¨ã€‚

        Args:
            simulation_progress_url (str): æ‰¹é‡æ¨¡æ‹Ÿçš„è¿›åº¦ URLï¼Œä¾‹å¦‚ "https://api.worldquantbrain.com/simulations/12345"

        Returns:
            list or None: å¦‚æœæˆåŠŸè¿”å› children åˆ—è¡¨ï¼Œå¦åˆ™è¿”å› None
        """
        try:
            simulation_progress = self.session.get(simulation_progress_url)
            simulation_progress.raise_for_status()

            # æ£€æŸ¥æ˜¯å¦åŒ…å« Retry-After å¤´ï¼Œè¡¨ç¤ºæœåŠ¡ç«¯æš‚æ—¶ä¸å¯ç”¨
            if simulation_progress.headers.get("Retry-After", 0) != 0:
                return None

            # è§£æå“åº”ï¼Œæå– children å’ŒçŠ¶æ€
            progress_data = simulation_progress.json()
            children = progress_data.get("children", [])
            if not children:
                self.logger.error("No children found in simulation progress response.")
                return None

            status = progress_data.get("status")
            self.logger.info(f"Simulation batch status: {status}, children count: {len(children)}")

            if status == "ERROR":
                self.logger.info(f"Simulation failed with ERROR status. Progress URL: {simulation_progress_url}")
            elif status != "COMPLETE":
                self.logger.info("Simulation not complete. Will check again later.")

            # æ‰“å°childrenå’Œrecord_idsçš„å…³è”æ—¥å¿—
            record_ids = self.active_simulations_dict.get(simulation_progress_url)
            if record_ids:
                self.logger.info(f"Associated children IDs: {children} with record IDs: {record_ids} for location: {simulation_progress_url}")
                self.active_simulations_dict.pop(simulation_progress_url, None)  # ç§»é™¤å·²å®Œæˆçš„æ˜ å°„,èŠ‚çœå†…å­˜
            else:
                self.logger.warning(f"No record_ids found for location: {simulation_progress_url}")
            return children

        except requests.exceptions.HTTPError as e:
            remove_status_codes = {400, 403, 404, 410}
            if e.response.status_code in remove_status_codes:
                self.logger.error(f"Simulation request failed with status {e.response.status_code}: {e}")
                self.active_simulations_dict.pop(simulation_progress_url, None)  # ç§»é™¤å¤„ç†å¤±è´¥çš„æ˜ å°„æ•°æ®,èŠ‚çœå†…å­˜
                return False
            else:
                self.logger.error(f"Failed to fetch simulation progress: {e}")
                
                self.session = config_manager.get_session()
                return None
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to fetch simulation progress: {e}")
            
            self.session = config_manager.get_session()
            return None

    def check_simulation_status(self):
        """
        æ£€æŸ¥åˆ°æœŸä»»åŠ¡ï¼Œå¤„ç†å®Œæˆ/å¤±è´¥/è¿›è¡Œä¸­çŠ¶æ€
        """
        now = time.time()
        checked_count = 0
        completed_count = 0
        failed_count = 0

        while self.simulation_heap and self.simulation_heap[0].next_check_time <= now:
            task = heapq.heappop(self.simulation_heap)
            result = self.check_simulation_progress(task.location_url)

            if result is None:
                # æœªå®Œæˆ æˆ– ä¸´æ—¶é”™è¯¯ â†’ æŒ‡æ•°é€€é¿é‡è¯•
                delay = self._calculate_backoff_delay(task.backoff_factor, task.retry_count, task.max_delay)
                task.retry_count += 1
                task.next_check_time = now + delay
                heapq.heappush(self.simulation_heap, task)
                checked_count += 1
                self.logger.debug(
                    f"Simulation {task.location_url} not done. "
                    f"Retry {task.retry_count}, next check in {delay:.1f}s"
                )

            elif result is False:
                # æ°¸ä¹…é”™è¯¯ â†’ æ”¾å¼ƒï¼Œä¸å†é‡è¯•
                self.logger.error(f"âŒ Permanently failed: {task.location_url}")
                failed_count += 1
                # ä¸å†å…¥å †

            else:
                # âœ… æ¨¡æ‹Ÿå®Œæˆï¼Œresult æ˜¯ children åˆ—è¡¨
                self.logger.info(f"âœ… Simulation completed: {task.location_url}")
                
                # --- å…¥åº“ children ---
                data_list = [
                    {
                        'child_id': child,
                        'submit_time': datetime.now(),
                        'status': 'pending',
                        'query_attempts': 0,
                        'last_query_time': None
                    }
                    for child in result
                ]
                try:
                    self.simulation_task_dao.batch_insert(data_list)
                    self.logger.info(f"ğŸ’¾ Inserted {len(result)} children for {task.location_url}")
                except Exception as e:
                    self.logger.error(f"Failed to insert children into DB: {e}")
                    # å³ä½¿å…¥åº“å¤±è´¥ï¼Œä»»åŠ¡ä¹Ÿç®—å®Œæˆï¼Œé¿å…é‡å¤æ’å…¥

                completed_count += 1

        # æ—¥å¿—ç»Ÿè®¡
        current_active = len(self.simulation_heap)
        self.logger.info(
            f"Checked: {checked_count}, "
            f"Completed: {completed_count}, "
            f"Failed: {failed_count}, "
            f"Active: {current_active}"
        )

    def _calculate_backoff_delay(self, backoff_factor, retry_count, max_delay: int) -> float:
        """è®¡ç®—ä¸‹æ¬¡æ£€æŸ¥å»¶è¿Ÿï¼Œå¸¦ jitter é˜²æ­¢é›ªå´©"""
        base = min(backoff_factor ** retry_count, max_delay)
        # æ·»åŠ éšæœºæŠ–åŠ¨ (Â±10%)
        jitter = random.uniform(0.9, 1.1)
        return base * jitter
    
    def save_state(self):
        # åªä¿å­˜ location_url åˆ—è¡¨
        urls = [task.location_url for task in self.simulation_heap]
        state = {
            "active_simulations": urls,
            "timestamp": datetime.now().strftime(self.TIMESTAMP_FORMAT)
        }
        with open(self.state_file, 'w') as f:
            json.dump(state, f)
        self.logger.info(f"Saved {len(urls)} active simulations to {self.state_file}")

    def fetch_pending_alphas_in_batches(self, batch_size):
        """ä»æ•°æ®åº“æ‰¹é‡æŸ¥è¯¢å¾…å›æµ‹alpha
        
        Args:
            batch_size (int): æ¯æ¬¡æŸ¥è¯¢çš„æ•°é‡
            
        Returns:
            list: å¾…å›æµ‹çš„alphaåˆ—è¡¨
        """
        if not self.region_set:
            self.logger.warning("No regions available in region_set")
            return []
            
        # è·å–å½“å‰regionï¼ˆç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        region = self.region_set[0]
        self.logger.info(f"Querying pending alphas for region: {region}, batch_size: {batch_size}")
        
        # ä½¿ç”¨DAOæŸ¥è¯¢æ•°æ®åº“
        alphas = self.alpha_list_pending_simulated_dao.fetch_and_lock_pending_by_region(
            region = region,
            limit = batch_size
        )
        
        # è½®è½¬region_setï¼šå°†å½“å‰regionç§»åˆ°æœ€åä¸€ä¸ª
        current_region = self.region_set.popleft()
        self.region_set.append(current_region)
        self.logger.info(f"Rotated region_set: moved {current_region} to the end")
        
        return alphas
    
    def _dynamic_sleep_and_check(self):
        if not self.simulation_heap:
            time.sleep(2)
            return

        now = time.time()
        nearest_check = self.simulation_heap[0].next_check_time
        sleep_time = max(0, nearest_check - now)

        if sleep_time > 0:
            self.logger.debug(f"ğŸ’¤ Sleeping {sleep_time:.2f}s until next check")
            time.sleep(sleep_time)

        self.check_simulation_status()  # å”¤é†’åç«‹å³æ£€æŸ¥

    def manage_simulations(self):
        """ç®¡ç†æ•´ä¸ªæ¨¡æ‹Ÿè¿‡ç¨‹"""
        if not self.session:
            self.logger.error("Failed to sign in. Exiting...")
            return

        try:
            while self.running:
                self._dynamic_sleep_and_check()
                self.load_new_alpha_and_simulate()
        except KeyboardInterrupt:
            self.logger.info("Manual interruption detected.")
